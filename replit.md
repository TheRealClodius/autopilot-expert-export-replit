# Multi-Agent Slack Autopilot Expert System

## Overview

This is a multi-agent AI system built with FastAPI that processes Slack messages using multiple specialized AI agents. The system uses Google Gemini models, vector search with Pinecone, and Redis for memory management to provide intelligent responses to user queries about project information.

## System Architecture

The system follows a multi-agent architecture with specialized agents handling different responsibilities:

- **Slack Gateway Agent**: Interfaces with Slack API for message processing
- **Orchestrator Agent**: Coordinates other agents and creates execution plans using Gemini 2.5 Pro
- **Client Agent**: Generates user-friendly responses using Gemini 2.5 Flash
- **Observer Agent**: Learns from conversations to improve system knowledge

The architecture supports both real-time message processing and background knowledge updates through Celery workers.

## Key Components

### Agents
- `agents/slack_gateway.py` - Handles Slack message ingestion and response delivery
- `agents/orchestrator_agent.py` - Main coordination agent using Gemini 2.5 Pro for query analysis
- `agents/client_agent.py` - Response generation agent using Gemini 2.5 Flash
- `agents/observer_agent.py` - Learning agent that updates knowledge based on conversations

### Tools
- `tools/vector_search.py` - Pinecone vector database search capabilities
- `tools/graph_query.py` - NetworkX-based relationship and dependency queries

### Services
- `services/memory_service.py` - Redis-based memory management for conversations and context
- `services/embedding_service.py` - SentenceTransformer embeddings and Pinecone operations
- `services/slack_connector.py` - Slack API integration with rate limiting
- `services/data_processor.py` - Message preprocessing for embedding storage

### Background Processing
- `workers/knowledge_update_worker.py` - Celery tasks for daily Slack data ingestion
- `celery_app.py` - Celery configuration with task queues

## Data Flow

1. **Message Reception**: Slack Gateway receives messages via webhook
2. **Query Analysis**: Orchestrator Agent analyzes query and creates execution plan
3. **Information Gathering**: Vector search and graph query tools retrieve relevant information
4. **Response Generation**: Client Agent generates persona-based response using Gemini Flash
5. **Learning**: Observer Agent analyzes conversations to update knowledge graph
6. **Background Updates**: Daily ingestion worker processes new Slack data

The system uses a two-step approach: first gathering information through vector search, then performing graph queries for relationships and ownership data.

## External Dependencies

### AI Services
- **Google Gemini**: Gemini 2.5 Pro for orchestration, Gemini 2.5 Flash for response generation
- **SentenceTransformers**: all-MiniLM-L6-v2 model for text embeddings

### Infrastructure
- **Pinecone**: Vector database for similarity search
- **Redis**: Memory management and caching
- **Slack API**: Message processing and response delivery

### Python Libraries
- FastAPI for web framework
- Celery for background task processing
- NetworkX for graph operations
- Pydantic for data validation

## Deployment Strategy

The application is designed for containerized deployment with the following components:

1. **Web Application**: FastAPI server handling Slack webhooks
2. **Celery Workers**: Background processing for knowledge updates
3. **Redis**: Memory and task queue backend
4. **External Services**: Pinecone, Slack API, and Gemini API integration

The system uses environment variables for configuration management and supports both development and production environments.

## Changelog

```
Changelog:
- June 27, 2025. Initial setup
```

## User Preferences

```
Preferred communication style: Simple, everyday language.
```