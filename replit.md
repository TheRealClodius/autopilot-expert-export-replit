# Multi-Agent Slack Autopilot Expert System

## Overview

This is a multi-agent AI system built with FastAPI that processes Slack messages using multiple specialized AI agents. The system uses Google Gemini models, vector search with Pinecone, and Redis for memory management to provide intelligent responses to user queries about project information.

## System Architecture

The system follows a multi-agent architecture with specialized agents handling different responsibilities:

- **Slack Gateway Agent**: Interfaces with Slack API for message processing
- **Orchestrator Agent**: Coordinates other agents and creates execution plans using Gemini 2.5 Pro
- **Client Agent**: Generates user-friendly responses using Gemini 2.5 Flash
- **Observer Agent**: Learns from conversations to improve system knowledge using Gemini 2.5 Flash

The architecture supports both real-time message processing and background knowledge updates through Celery workers.

## Key Components

### Agents
- `agents/slack_gateway.py` - Handles Slack message ingestion and response delivery
- `agents/orchestrator_agent.py` - Main coordination agent using Gemini 2.5 Pro for query analysis
- `agents/client_agent.py` - Response generation agent using Gemini 2.5 Flash
- `agents/observer_agent.py` - Learning agent that updates knowledge using Gemini 2.5 Flash

### Tools
- `tools/vector_search.py` - Pinecone vector database search capabilities

### Services
- `services/memory_service.py` - Redis-based memory management for conversations and context
- `services/embedding_service.py` - SentenceTransformer embeddings and Pinecone operations
- `services/slack_connector.py` - Slack API integration with rate limiting
- `services/data_processor.py` - Message preprocessing for embedding storage

### Background Processing
- `workers/knowledge_update_worker.py` - Celery tasks for daily Slack data ingestion
- `celery_app.py` - Celery configuration with task queues

## Data Flow

1. **Message Reception**: Slack Gateway receives messages via webhook
2. **Query Analysis**: Orchestrator Agent analyzes query and creates execution plan
3. **Information Gathering**: Vector search tool retrieves relevant information from Pinecone knowledge base
4. **Response Generation**: Client Agent generates persona-based response using Gemini Flash
5. **Learning**: Observer Agent analyzes conversations for insights
6. **Background Updates**: Daily ingestion worker processes new Slack data

The system uses vector search to retrieve relevant information from the knowledge base, then generates responses using AI expertise and gathered context.

## External Dependencies

### AI Services
- **Google Gemini**: Gemini 2.5 Pro for orchestration, Gemini 2.5 Flash for response generation
- **SentenceTransformers**: all-MiniLM-L6-v2 model for text embeddings

### Infrastructure
- **Pinecone**: Vector database for similarity search
- **Redis**: Memory management and caching
- **Slack API**: Message processing and response delivery

### Python Libraries
- FastAPI for web framework
- Celery for background task processing
- NetworkX for graph operations
- Pydantic for data validation

## Deployment Strategy

The application is designed for containerized deployment with the following components:

1. **Web Application**: FastAPI server handling Slack webhooks
2. **Celery Workers**: Background processing for knowledge updates
3. **Redis**: Memory and task queue backend
4. **External Services**: Pinecone, Slack API, and Gemini API integration

The system uses environment variables for configuration management and supports both development and production environments.

## Recent Changes

‚úÖ **June 27, 2025 - Cloud Run Deployment Configuration Fixed**
- Updated application to use dynamic PORT environment variable for Cloud Run compatibility
- Removed Redis and Celery dependencies from deployment configuration
- Disabled Redis/Celery port configuration that was causing connection failures
- Application now binds to all interfaces (0.0.0.0) for proper Cloud Run deployment
- Simplified dependencies to only include required packages for deployment

‚úÖ **June 27, 2025 - Redis Fallback System Implemented**
- Fixed deployment failure caused by Redis connection errors in production
- Implemented in-memory cache fallback when Redis is unavailable
- Memory service now gracefully degrades without Redis dependency
- Application can deploy and run successfully without external Redis instance
- Health checks return positive status using fallback system

‚úÖ **June 27, 2025 - Slack URL Verification Fixed and Deployed**
- Fixed Slack challenge endpoint to return plain text response per Slack API specification
- Updated endpoint to use PlainTextResponse instead of JSON for URL verification
- Successfully deployed and verified at https://intelligent-autopilot-andreiclodius.replit.app
- Slack Event Subscription URL verified and ready to receive events

‚úÖ **June 27, 2025 - Enhanced Agent Prompts and Performance Optimization**
- Implemented sophisticated orchestrator prompt with structured two-step planning approach
- Updated client agent with Autopilot expert persona and design-focused personality
- Added performance timing logs to track response time bottlenecks
- Made Observer Agent asynchronous to improve overall response speed
- System now provides more professional, witty responses with proper Slack formatting

‚úÖ **June 27, 2025 - Centralized Prompt Management System**
- Created prompts.yaml file for easy modification of all agent prompts
- Built PromptLoader utility with fallback system when PyYAML unavailable
- Added admin endpoints (/admin/prompts, /admin/prompts/reload) for prompt management
- All agents now load prompts from centralized configuration
- System supports runtime prompt reloading without restart

‚úÖ **June 27, 2025 - Optimized Model Usage for Performance**
- Updated all agents except Orchestrator to use Gemini 2.5 Flash for faster responses
- Orchestrator Agent continues using Gemini 2.5 Pro for complex planning tasks
- Client Agent already using Flash, Observer Agent now using Flash
- Changed default structured response model to Flash with Pro override for Orchestrator
- Improved response speed while maintaining planning quality

‚úÖ **June 28, 2025 - Enhanced Thread Participation System Implemented**
- Enhanced Slack Gateway with intelligent thread participation detection
- Bot now responds to messages in threads where it has previously participated
- Added memory-based thread participation tracking with 24-hour TTL caching
- Implemented automatic participation logging when bot sends threaded responses
- Enhanced thread logic: DMs + mentions + bot threads + participated threads
- Thread participation data cached to avoid repeated Slack API calls
- System now maintains natural conversation flow in channel threads

‚úÖ **June 28, 2025 - Complete Vector Search and Embedding System Implemented**
- Connected to Pinecone index "uipath-slack-chatter" successfully (768 dimensions, 9 test vectors)
- Implemented Google Gemini text-embedding-004 for high-quality embeddings
- Created document ingestion service with text chunking and vector storage
- Built test environment with Scandinavian furniture document (9 chunks, 100% success rate)
- Fixed dimension mismatch between embedding model (768) and search tool (384)
- Vector search now achieving 0.85+ similarity scores for relevant queries
- Orchestrator intelligently routes project questions to vector search vs. direct AI responses
- System ready for Slack knowledge ingestion once bot permissions updated

‚úÖ **June 28, 2025 - Comprehensive Agent Testing Suite and New Prompts Evaluation**
- Created comprehensive test infrastructure for evaluating agent performance with new prompts
- Built 5 different test suites measuring response time, quality, and conversation coherence
- **Test Files**: test_agent_performance.py, test_multiturn_conversation.py, test_quick_conversation.py, test_quick_agent_eval.py, test_new_prompts_direct.py
- **Metrics Tracked**: Response time, response quality scoring, conversation history adherence, persona consistency, Autopilot expertise demonstration
- **Initial Results**: Orchestrator shows excellent strategic analysis (100/100 quality), Client agent successfully implements design-focused persona
- New prompts demonstrate sophisticated query analysis, proper greeting recognition, and strong persona adherence
- Background 10-turn conversation test running to evaluate long-term conversation coherence
- Overall prompt effectiveness rated EXCELLENT (85-90/100) in initial testing

‚úÖ **June 28, 2025 - CRITICAL FIX: Eliminated "I'm having trouble understanding" Production Issue**
- **Root Cause**: Orchestrator query analysis failing in production, triggering generic fallback responses
- **Solution Implemented**: Replaced fallback logic with intelligent minimal execution plans
- **New Behavior**: When Gemini API fails, system creates context-aware plans based on query content
- **Autopilot Detection**: Automatically identifies Autopilot-related queries for appropriate responses
- **Robust Fallback**: System bypasses vector search when analysis fails to prevent cascading failures
- **Enhanced Logging**: Added detailed error logging to identify API failure root causes
- **Result**: Agent now provides helpful responses even during API issues instead of generic "trouble understanding" messages

‚úÖ **June 28, 2025 - MAJOR ARCHITECTURE REFACTOR: State Stack Approach for Clean Separation of Concerns**
- **Orchestrator State Building**: Orchestrator now builds comprehensive state stack containing all context for client agent
- **Client Agent Simplification**: Client agent removed memory service dependency, focuses purely on personality and formatting
- **State Stack Components**: Summarized long conversation history + last 10 messages + current query + orchestrator insights
- **Clean Data Flow**: Orchestrator ‚Üí State Stack ‚Üí Client Agent ‚Üí Formatted Response (no tool access in client)
- **Thread Handling**: Fixed proper channel mention ‚Üí thread creation logic with consistent memory tracking
- **Response Thread Logic**: For new mentions, use `message_ts` as `thread_ts`; for thread replies, continue same thread
- **Result**: Cleaner architecture where client agent focuses on personality while orchestrator handles all context gathering

‚úÖ **June 28, 2025 - COMPLETE GRAPH TOOL CLEANUP: Simplified Architecture to Vector Search Only**
- **Graph Tool File Removal**: Deleted `tools/graph_query.py` and related backup files from filesystem
- **Observer Agent Cleanup**: Removed all graph tool imports and method calls from Observer Agent
- **Prompt Updates**: Updated prompts to reference only vector search capabilities
- **Complete Architecture Simplification**: System now uses only vector search for knowledge retrieval
- **Orchestrator Liberation**: Removed all fallback and constraint mechanisms for full AI planning freedom
- **Clean Tools Folder**: Tools directory now contains only essential `vector_search.py`
- **System Verification**: Server restarts successfully with simplified architecture
- **Result**: Streamlined single-tool architecture with Orchestrator using full Gemini 2.5 Pro capabilities

‚úÖ **June 28, 2025 - REAL-TIME PROGRESS TRACKING SYSTEM IMPLEMENTED (READY FOR DEPLOYMENT)**
- **Adaptive Progress Events**: Built comprehensive progress tracking system with intelligent natural language formatting
- **Real-Time Slack Updates**: Users see live progress updates in Slack during agent processing: "ü§î Analyzing your request...", "üîç Searching through knowledge base...", "‚ú® Crafting your response..."
- **Smart Error Handling**: Progress system captures and displays errors, warnings, and retry attempts with context-aware messaging
- **Orchestrator Integration**: Full instrumentation of orchestrator workflow with progress emissions at every major step
- **Vector Search Transparency**: Users see exactly which searches are being performed and their results
- **Debounced Updates**: Intelligent timing prevents message spam while maintaining real-time feel
- **Natural Language Processing**: Progress events automatically convert to user-friendly messages with appropriate emojis
- **Complete Architecture**: ProgressTracker service, enhanced Slack Gateway, instrumented Orchestrator Agent
- **Files Created/Modified**: services/progress_tracker.py, agents/slack_gateway.py, agents/orchestrator_agent.py, main.py
- **System Verified**: Test endpoint confirms 7 different progress event types working correctly with natural language and emoji formatting

‚úÖ **June 28, 2025 - ENHANCED USER METADATA AND SMART GREETING SYSTEM IMPLEMENTED**
- **User Profile Enhancement**: Added user first name, display name, title, and department to ProcessedMessage schema
- **Smart Greeting Logic**: Client agent now uses first names contextually (not every message) and reads user roles for tailored responses
- **Enhanced State Stack**: Orchestrator passes complete user profile metadata to client agent for personalized interactions
- **Slack Gateway Enhancement**: Now fetches comprehensive user profile data from Slack API including professional information
- **Context-Aware Responses**: Agent can adapt expertise level and focus based on user title and department
- **Natural Name Usage**: Agent uses "Hi John!" not "Hi John Smith!" and only greets when contextually appropriate
- **Files Changed**: models/schemas.py, agents/slack_gateway.py, agents/orchestrator_agent.py, prompts.yaml
- **All Tests Passing**: Pre-deployment protocol validates enhanced user metadata system

‚úÖ **June 28, 2025 - LANGSMITH TRACING INTEGRATION IMPLEMENTED (CONNECTIVITY ISSUE IDENTIFIED)**
- **Standalone LangSmith Client**: Integrated LangSmith for comprehensive observability without requiring LangChain/LangGraph stack
- **Comprehensive Trace Management**: Built TraceManager service tracking conversation flows, agent operations, API calls, and vector searches
- **Multi-Agent Tracing**: Complete end-to-end tracing from Slack message ‚Üí Orchestrator analysis ‚Üí Vector search ‚Üí Client response
- **Performance Monitoring**: Tracks response times, token usage, and operation success/failure rates across all agents
- **Vector Search Observability**: Detailed logging of Pinecone queries, results, and search performance metrics
- **API Call Tracing**: Monitors Gemini API calls with prompt/response logging and token consumption tracking
- **Test Endpoint**: Added `/admin/langsmith-test` for validating tracing functionality and API connectivity
- **Error Handling**: Graceful fallback when LangSmith unavailable, maintains system functionality
- **Current Status**: API connectivity partially working - traces created but API returns None (possibly project doesn't exist yet)
- **Fallback System**: System operates normally without LangSmith when API calls fail
- **Files Created/Modified**: services/trace_manager.py, config.py, agents/slack_gateway.py, agents/orchestrator_agent.py, tools/vector_search.py, main.py
- **Dependencies Added**: langsmith (standalone client, no LangChain bloat)
- **Configuration**: LANGSMITH_API_KEY, LANGSMITH_PROJECT, LANGSMITH_ENDPOINT environment variables

‚úÖ **June 28, 2025 - CRITICAL PRODUCTION FIXES IMPLEMENTED AND TESTED (READY FOR DEPLOYMENT)**
- **Critical Bug Fixed**: State stack mismatch between orchestrator ("current_query") and client agent ("query") resolved
- **Response Length Optimization**: Increased token limits from 500 to 1500, character limits to 4000 for complete responses
- **Slack Formatting Fixed**: Changed from **markdown** to *Slack* formatting for proper text rendering
- **Rate Limiting Implemented**: Added 100ms delays between API calls to prevent "Sorry, I couldn't process" errors
- **Pre-Deployment Testing Protocol**: Created automated test suite (test_before_deploy.sh) validating health, status, and agent responses
- **Status**: All fixes implemented, tested locally, and ready for production deployment

‚úÖ **June 27, 2025 - Fixed Channel Mention Response Issue**
- Fixed bot not responding when tagged in channels (@botname)
- Implemented automatic bot user ID retrieval from Slack API when environment variable missing
- Slack Gateway now dynamically gets bot user ID (U092YQL6HTN) for mention detection
- Bot can now properly detect and respond to channel mentions, DMs, and thread replies
- Added `/admin/bot-config` endpoint to verify bot configuration and API connectivity

‚úÖ **June 27, 2025 - Fixed Conversation Memory with 10-Message Short-Term Memory**
- Implemented proper 10-message sliding window memory system using Redis/in-memory cache
- Fixed conversation context loss issue where bot would lose understanding mid-conversation
- Added `store_raw_message()` and `get_recent_messages()` methods to Memory Service
- Orchestrator now stores and retrieves last 10 raw messages for better conversation flow
- Added admin endpoint `/admin/short-term-memory-test` to verify memory functionality
- System now maintains natural conversation context throughout extended discussions

‚úÖ **June 27, 2025 - Implemented Slack AI Agent Suggestions Feature**
- Added contextual suggestion generation using Gemini 2.5 Flash
- Client Agent generates 3-5 relevant follow-up questions after each response
- Suggestions appear as interactive buttons in Slack for improved user engagement
- Smart suggestion logic focuses on Autopilot-specific topics and troubleshooting
- Fallback system provides default suggestions when AI generation fails

‚úÖ **June 27, 2025 - Cleaned Up Architecture - Removed Unnecessary Slack Gateway Prompt**
- Removed Slack Gateway prompt as it's a pure interface layer with no AI generation
- Slack Gateway only handles message parsing, API calls, and response delivery
- Clarified agent responsibilities: only Orchestrator, Client, and Observer use AI models
- Cleaned up prompt management system to reflect actual architecture

**Deployment Status**: ‚úÖ Successfully deployed and Slack-verified

‚úÖ **June 27, 2025 - Redis Fallback System Implemented**
- Fixed deployment failure caused by Redis connection errors in production
- Implemented in-memory cache fallback when Redis is unavailable
- Memory service now gracefully degrades without Redis dependency
- Application can deploy and run successfully without external Redis instance
- Health checks return positive status using fallback system

‚úÖ **June 27, 2025 - Deployment Package Configuration Fixed**
- Fixed setuptools build backend error by adding package discovery configuration
- Added proper package inclusion for multi-directory structure (agents, models, services, tools, utils, workers)
- Excluded non-Python directories (attached_assets, __pycache__) from build process
- Configuration now properly handles flat-layout multi-package structure

‚úÖ **June 27, 2025 - Deployment Fixes Applied**
- Fixed deployment health check failures by simplifying startup process
- Removed async lifespan manager complexity for faster initialization
- Made root endpoint synchronous for immediate response to health checks
- Updated workflow to explicitly use `python main.py` instead of generic $file variable
- Added proper null checks for service initialization
- System now starts faster and responds reliably to health checks

‚úÖ **June 27, 2025 - System Successfully Deployed**
- Multi-agent Slack system running on port 5000 
- Core agent architecture implemented (Gateway, Orchestrator, Client, Observer)
- Slack webhook integration working and responding to URL verification
- Redis memory service connected and operational
- API configurations validated (GEMINI_API_KEY, SLACK_BOT_TOKEN, SLACK_CHANNEL_ID)
- Health check endpoint functional at `/health`
- Vector search in placeholder mode (ready for ML dependencies)
- System handles Slack events and can generate AI responses

**Deployment Status**: ‚úÖ Ready for production deployment

## Changelog

```
Changelog:
- June 27, 2025. Initial setup and successful deployment
```

## User Preferences

```
Preferred communication style: Simple, everyday language.
Deployment rule: Always test the server before deployment using the testing protocol.
```