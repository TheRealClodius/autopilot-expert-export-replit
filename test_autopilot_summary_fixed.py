#!/usr/bin/env python3
"""
Test the complete "Autopilot for Everyone" summary generation flow
with the MCP parameter fix applied.

This test replicates the exact user scenario from the Slack screenshot:
"Can you create a summary of the autopilot for everyone project based on
all confluence pages you can find about it?"
"""

import asyncio
import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from agents.orchestrator_agent import OrchestratorAgent
from agents.client_agent import ClientAgent
from models.schemas import ProcessedMessage
from services.memory_service import MemoryService
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

async def test_autopilot_summary():
    """Test complete flow for Autopilot for Everyone summary generation"""
    print("ðŸš€ TESTING COMPLETE AUTOPILOT SUMMARY GENERATION FLOW")
    print("=" * 60)
    
    # Initialize services
    memory_service = MemoryService()
    orchestrator = OrchestratorAgent(memory_service)
    client_agent = ClientAgent()
    
    # Create the exact message from the user scenario
    test_message = ProcessedMessage(
        channel_id="C087QKECFKQ",
        channel_name="general",
        user_id="U_ANDREI_CLODIUS",
        text="Can you create a summary of the autopilot for everyone project based on all confluence pages you can find about it?",
        message_ts="1751182507.951000",
        thread_ts=None,
        user_name="andrei.clodius",
        user_first_name="Andrei",
        user_display_name="Andrei Clodius",
        user_title="Product Manager",
        user_department="Product"
    )
    
    print(f"ðŸ“ Query: {test_message.text}")
    print(f"ðŸ‘¤ User: {test_message.user_first_name} ({test_message.user_title})")
    print("\n" + "=" * 60)
    
    try:
        # Step 1: Orchestrator Analysis
        print("ðŸ§  Step 1: Orchestrator Analysis")
        print("-" * 30)
        
        execution_plan = await orchestrator._analyze_query_and_plan(test_message)
        
        if not execution_plan:
            print("âŒ FAILED: No execution plan returned from orchestrator")
            return False
        
        print(f"âœ… Analysis: {execution_plan.get('analysis', 'No analysis')[:100]}...")
        print(f"âœ… Tools needed: {execution_plan.get('tools_needed', [])}")
        
        # Step 1.5: Execute the plan to get gathered information
        print(f"\nâš¡ Step 1.5: Executing Plan")
        print("-" * 30)
        
        gathered_info = await orchestrator._execute_plan(execution_plan, test_message)
        
        if not gathered_info:
            print("âŒ FAILED: No gathered information from plan execution")
            return False
        
        # Check if Atlassian search was used
        atlassian_results = gathered_info.get("atlassian_results", [])
        if not atlassian_results:
            print("âŒ FAILED: No Atlassian results found in gathered information")
            return False
        
        print(f"âœ… Found {len(atlassian_results)} Confluence pages")
        
        # Step 2: Client Agent Response Generation
        print(f"\nâœ¨ Step 2: Client Agent Response Generation")
        print("-" * 40)
        
        # Create state stack for client agent
        state_stack = {
            "query": test_message.text,
            "user_context": {
                "first_name": test_message.user_first_name,
                "title": test_message.user_title,
                "department": test_message.user_department
            },
            "conversation_history": {"recent_exchanges": []},
            "orchestrator_analysis": {
                "intent": execution_plan.get("analysis", ""),
                "tools_used": execution_plan.get("tools_needed", []),
                "atlassian_results": atlassian_results
            }
        }
        
        response = await client_agent.generate_response(state_stack)
        
        if not response:
            print("âŒ FAILED: No response generated by client agent")
            return False
        
        # Display the response
        print("ðŸ“‹ GENERATED RESPONSE:")
        print("=" * 60)
        print(response.get("message", "No message content"))
        print("=" * 60)
        
        # Validate response quality
        response_text = response.get("message", "")
        validation_checks = {
            "Has content": len(response_text) > 100,
            "Mentions Autopilot": "autopilot" in response_text.lower(),
            "Has source links": "<https://" in response_text,
            "Professional tone": "summary" in response_text.lower() or "project" in response_text.lower()
        }
        
        print("\nðŸ” RESPONSE VALIDATION:")
        print("-" * 30)
        for check, passed in validation_checks.items():
            status = "âœ…" if passed else "âŒ"
            print(f"{status} {check}: {passed}")
        
        all_passed = all(validation_checks.values())
        
        if all_passed:
            print(f"\nðŸŽ‰ SUCCESS: Complete Autopilot summary generation working correctly!")
            print(f"âœ… Orchestrator correctly routed to Confluence search")
            print(f"âœ… MCP integration returning real UiPath data")  
            print(f"âœ… Client agent generating professional summary with source links")
            return True
        else:
            print(f"\nâš ï¸ PARTIAL SUCCESS: Flow working but response quality needs improvement")
            return False
            
    except Exception as e:
        print(f"\nâŒ ERROR: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    asyncio.run(test_autopilot_summary())